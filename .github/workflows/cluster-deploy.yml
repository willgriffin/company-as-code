name: Deploy Kubernetes Cluster

# Prevent multiple workflows from running simultaneously to avoid Terraform state conflicts
concurrency:
  group: terraform-deploy
  cancel-in-progress: false

on:
  workflow_dispatch:
    inputs:
      destroy:
        description: 'Destroy cluster instead of creating it'
        required: false
        default: false
        type: boolean
      terraform_version:
        description: 'Terraform version to use (defaults to version from tool-versions.txt)'
        required: false
        type: string
  push:
    branches: [main]
    paths:
      - 'config.yaml'
      - 'terraform/**'
      - 'flux/**'
      - '.github/workflows/cluster-deploy.yml'
      - '!flux/**/secrets.enc.yaml'
      - '!flux/**/ingress*.yaml'

env:
  TF_IN_AUTOMATION: true

jobs:
  validate-config:
    name: Validate Configuration
    runs-on: ubuntu-latest
    timeout-minutes: 5
    # Skip this job if IS_TEMPLATE repository variable is set to 'true'
    if: vars.IS_TEMPLATE != 'true'
    outputs:
      config-valid: ${{ steps.validate.outputs.valid }}
      primary-domain: ${{ steps.parse-config.outputs.primary-domain }}
      cluster-name: ${{ steps.parse-config.outputs.cluster-name }}
      region: ${{ steps.parse-config.outputs.region }}
      terraform-version: ${{ steps.terraform-version.outputs.version }}
    steps:
      - uses: actions/checkout@v4
      
      - name: Validate Repository Configuration
        id: validate
        uses: ./.github/actions/validate-config
        with:
          digitalocean-token: ${{ secrets.DIGITALOCEAN_TOKEN }}
          github-token: ${{ secrets.GH_TOKEN }}
          sops-age-private-key: ${{ secrets.SOPS_AGE_PRIVATE_KEY }}
      
      - name: Parse Configuration
        id: parse-config
        run: |
          # Parse config.yaml and extract key values
          PRIMARY_DOMAIN=$(yq eval '.domain.primary' config.yaml)
          CLUSTER_NAME=$(yq eval '.cluster.name' config.yaml)
          REGION=$(yq eval '.cluster.region' config.yaml)
          
          echo "primary-domain=$PRIMARY_DOMAIN" >> $GITHUB_OUTPUT
          echo "cluster-name=$CLUSTER_NAME" >> $GITHUB_OUTPUT
          echo "region=$REGION" >> $GITHUB_OUTPUT
      
      - name: Determine Terraform Version
        id: terraform-version
        run: |
          # Use input version if provided, otherwise read from tool-versions.txt
          if [ -n "${{ github.event.inputs.terraform_version }}" ]; then
            TF_VERSION="${{ github.event.inputs.terraform_version }}"
          else
            TF_VERSION=$(grep '^terraform=' tool-versions.txt | cut -d'=' -f2)
          fi
          
          echo "version=$TF_VERSION" >> $GITHUB_OUTPUT
          echo "Using Terraform version: $TF_VERSION"

  setup-secrets:
    name: Generate and Setup Secrets
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: validate-config
    if: needs.validate-config.outputs.config-valid == 'true'
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup tools
        uses: ./.github/actions/setup-tools
        with:
          tools: 'age,sops,yq,kubectl,flux,gomplate,doctl'
      
      - name: Process Domain Templates
        run: |
          echo "Processing domain templates with gomplate..."
          
          # Process all YAML files that contain gomplate template syntax
          find flux/clusters/cumulus -name "*.yaml" -type f | while read -r file; do
            if grep -q "(datasource \"config\")" "$file" 2>/dev/null; then
              echo "  Processing: $file"
              # Create temporary file for gomplate output
              temp_file=$(mktemp)
              
              # Process template with config.yaml as datasource
              gomplate --datasource config=config.yaml --file "$file" --out "$temp_file"
              
              # Replace original file with processed version
              mv "$temp_file" "$file"
            fi
          done
          
          echo "âœ“ Domain templates processed successfully"
      
      - name: Generate SOPS Age Key
        id: generate-age-key
        env:
          SOPS_KEY: ${{ secrets.SOPS_AGE_PRIVATE_KEY }}
        run: |
          # Generate age key if not already set
          if [ -z "$SOPS_KEY" ]; then
            age-keygen > age.key 2>&1
            # Extract the private key (lines that start with AGE-SECRET-KEY)
            PRIVATE_KEY=$(grep "^AGE-SECRET-KEY" age.key)
            # Extract just the age key part after "Public key: "
            PUBLIC_KEY=$(awk '/^Public key:/ {print $3}' age.key)
            
            echo "private-key=$PRIVATE_KEY" >> $GITHUB_OUTPUT
            echo "public-key=$PUBLIC_KEY" >> $GITHUB_OUTPUT
            echo "age-key-generated=true" >> $GITHUB_OUTPUT
            
            # Update .sops.yaml with new public key
            sed -i "s/age: age[a-z0-9]*/age: $PUBLIC_KEY/g" .sops.yaml
          else
            echo "age-key-generated=false" >> $GITHUB_OUTPUT
            # Get public key from existing private key
            echo "$SOPS_KEY" | age-keygen -y > public.key
            PUBLIC_KEY=$(cat public.key)
            echo "public-key=$PUBLIC_KEY" >> $GITHUB_OUTPUT
          fi
      
      - name: Setup Spaces Access Keys
        id: setup-spaces-keys
        env:
          DIGITALOCEAN_TOKEN: ${{ secrets.DIGITALOCEAN_TOKEN }}
          SPACES_ACCESS_KEY_ID: ${{ secrets.SPACES_ACCESS_KEY_ID }}
          SPACES_SECRET_ACCESS_KEY: ${{ secrets.SPACES_SECRET_ACCESS_KEY }}
        run: |
          # Check if Spaces credentials already exist
          if [[ -z "$SPACES_ACCESS_KEY_ID" || -z "$SPACES_SECRET_ACCESS_KEY" ]]; then
            echo "Creating DigitalOcean Spaces access keys for Terraform state storage..."
            
            # Create unique key name with timestamp
            KEY_NAME="terraform-state-$(date +%s)"
            
            # Create Spaces access key with full access (needed for Terraform state)
            # Retry this API call as it can hit rate limits with exponential backoff
            create_spaces_key() {
              doctl spaces keys create "$KEY_NAME" \
                --grants "bucket=;permission=fullaccess" \
                --output json \
                --access-token "$DIGITALOCEAN_TOKEN"
            }
            
            retry_count=0
            max_retries=5
            while [ $retry_count -lt $max_retries ]; do
              OUTPUT=$(create_spaces_key 2>&1)
              exit_code=$?
              
              if [ $exit_code -eq 0 ]; then
                break
              else
                retry_count=$((retry_count + 1))
                if [ $retry_count -lt $max_retries ]; then
                  wait_time=$((2 ** retry_count))
                  echo "Attempt $retry_count/$max_retries failed (exit code: $exit_code), retrying in ${wait_time}s..."
                  sleep $wait_time
                else
                  echo "Failed to create Spaces access key after $max_retries attempts"
                  exit $exit_code
                fi
              fi
            done
            
            if [[ $exit_code -eq 0 ]]; then
              # Extract credentials from JSON output
              ACCESS_KEY=$(echo "$OUTPUT" | jq -r '.access_key')
              SECRET_KEY=$(echo "$OUTPUT" | jq -r '.secret_key')
              
              # Validate we got valid credentials
              if [[ "$ACCESS_KEY" != "null" && "$SECRET_KEY" != "null" && -n "$ACCESS_KEY" && -n "$SECRET_KEY" ]]; then
                echo "âœ“ Successfully created Spaces access keys"
                echo "spaces-key-created=true" >> $GITHUB_OUTPUT
                echo "access-key=$ACCESS_KEY" >> $GITHUB_OUTPUT
                echo "secret-key=$SECRET_KEY" >> $GITHUB_OUTPUT
                
                # Mask the sensitive values in logs
                echo "::add-mask::$ACCESS_KEY"
                echo "::add-mask::$SECRET_KEY"
              else
                echo "âŒ Failed to extract valid credentials from doctl output"
                echo "Error: Unable to extract credentials. Please check the doctl command and permissions."
                exit 1
              fi
            else
              echo "âŒ Failed to create Spaces access keys"
              echo "This might be due to insufficient permissions or rate limits"
              exit 1
            fi
          else
            echo "âœ“ Spaces access keys already exist, skipping creation"
            echo "spaces-key-created=false" >> $GITHUB_OUTPUT
          fi
      
      - name: Generate Application Secrets
        env:
          DIGITALOCEAN_TOKEN: ${{ secrets.DIGITALOCEAN_TOKEN }}
          GITHUB_TOKEN: ${{ secrets.GH_TOKEN }}
          SOPS_AGE_PRIVATE_KEY: ${{ secrets.SOPS_AGE_PRIVATE_KEY }}
          GENERATED_AGE_KEY: ${{ steps.generate-age-key.outputs.private-key }}
        run: |
          # Create temporary .envrc.secrets for secret generation
          cat > .envrc.secrets << EOF
          export DIGITALOCEAN_TOKEN="${DIGITALOCEAN_TOKEN}"
          export GITHUB_TOKEN="${GITHUB_TOKEN}"
          export SOPS_AGE_PRIVATE_KEY="${SOPS_AGE_PRIVATE_KEY:-${GENERATED_AGE_KEY}}"
          
          # Placeholder values that will be generated
          export KEYCLOAK_DB_PASSWORD="placeholder"
          export KEYCLOAK_ADMIN_PASSWORD="placeholder"
          export MATTERMOST_DB_PASSWORD="placeholder"
          export MATTERMOST_OAUTH_CLIENT_ID="placeholder"
          export MATTERMOST_OAUTH_CLIENT_SECRET="placeholder"
          export NEXTCLOUD_DB_PASSWORD="placeholder"
          export NEXTCLOUD_OIDC_CLIENT_ID="placeholder"
          export NEXTCLOUD_OIDC_CLIENT_SECRET="placeholder"
          export MAILU_OAUTH2_CLIENT_ID="placeholder"
          export MAILU_OAUTH2_CLIENT_SECRET="placeholder"
          export MAILU_OAUTH2_COOKIE_SECRET="placeholder"
          EOF
          
          # Generate secure passwords and secrets
          ./scripts/generate-secrets
      
      - name: Update GitHub Secrets
        if: steps.generate-age-key.outputs.age-key-generated == 'true' || steps.setup-spaces-keys.outputs.spaces-key-created == 'true'
        env:
          GH_TOKEN: ${{ secrets.GH_TOKEN }}
        run: |
          # Update SOPS_AGE_PRIVATE_KEY secret if it was generated
          if [[ "${{ steps.generate-age-key.outputs.age-key-generated }}" == "true" ]]; then
            echo "Updating SOPS_AGE_PRIVATE_KEY secret..."
            echo "${{ steps.generate-age-key.outputs.private-key }}" | \
              gh secret set SOPS_AGE_PRIVATE_KEY --repo ${{ github.repository }}
            echo "âœ“ SOPS_AGE_PRIVATE_KEY updated"
          fi
          
          # Update Spaces access keys if they were generated
          if [[ "${{ steps.setup-spaces-keys.outputs.spaces-key-created }}" == "true" ]]; then
            echo "Updating Spaces access key secrets..."
            echo "${{ steps.setup-spaces-keys.outputs.access-key }}" | \
              gh secret set SPACES_ACCESS_KEY_ID --repo ${{ github.repository }}
            echo "${{ steps.setup-spaces-keys.outputs.secret-key }}" | \
              gh secret set SPACES_SECRET_ACCESS_KEY --repo ${{ github.repository }}
            echo "âœ“ Spaces access keys updated"
          fi
      
      - name: Commit updated .sops.yaml
        if: steps.generate-age-key.outputs.age-key-generated == 'true'
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add .sops.yaml
          git commit -m "feat: update SOPS configuration with new age key" || exit 0
          git push

  deploy-infrastructure:
    name: Deploy Infrastructure
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: [validate-config, setup-secrets]
    if: github.event.inputs.destroy != 'true'
    outputs:
      backup-file: ${{ steps.store-backup.outputs.backup-file }}
      backup-created: ${{ steps.store-backup.outputs.backup-created }}
    defaults:
      run:
        working-directory: terraform/digitalocean
    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ github.sha }}
      
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ needs.validate-config.outputs.terraform-version }}
      
      - name: Install doctl
        uses: digitalocean/action-doctl@v2
        with:
          token: ${{ secrets.DIGITALOCEAN_TOKEN }}
      
      - name: Parse Configuration for Terraform
        id: parse-config
        run: |
          cd ../../
          
          # Parse config.yaml and create terraform.tfvars
          PRIMARY_DOMAIN=$(yq eval '.domain.primary' config.yaml)
          
          # Check if domain already exists in DigitalOcean (with retry for API rate limits)
          retry_count=0
          max_retries=5
          while [ $retry_count -lt $max_retries ]; do
            doctl compute domain get "$PRIMARY_DOMAIN" >/dev/null 2>&1
            exit_code=$?
            
            if [ $exit_code -eq 0 ]; then
              echo "âœ… Domain $PRIMARY_DOMAIN already exists, will skip creation"
              SKIP_DOMAIN_CREATION=true
              break
            elif [ $exit_code -eq 1 ]; then
              echo "â„¹ï¸ Domain $PRIMARY_DOMAIN does not exist, will create it"
              SKIP_DOMAIN_CREATION=false
              break
            else
              retry_count=$((retry_count + 1))
              if [ $retry_count -lt $max_retries ]; then
                wait_time=$((2 ** retry_count))
                echo "API call failed (exit code: $exit_code), retrying in ${wait_time}s... (attempt $retry_count/$max_retries)"
                sleep $wait_time
              else
                echo "Failed to check domain after $max_retries attempts"
                exit 1
              fi
            fi
          done
          
          # Check for configuration conflicts
          # If skip_domain_creation is explicitly set to true but domain doesn't exist, fail
          EXPLICIT_SKIP=$(yq eval '.advanced.terraform.skip_domain_creation // false' config.yaml 2>/dev/null || echo "false")
          if [[ "$EXPLICIT_SKIP" == "true" && "$SKIP_DOMAIN_CREATION" == "false" ]]; then
            echo "âŒ Error: skip_domain_creation is set to true in config.yaml but domain $PRIMARY_DOMAIN does not exist in DigitalOcean"
            echo "Either:"
            echo "  1. Create the domain in DigitalOcean first, or"
            echo "  2. Set skip_domain_creation to false to allow domain creation"
            exit 1
          fi
          
          cat > terraform/digitalocean/auto.tfvars << EOF
          cluster_name = "$(yq eval '.cluster.name' config.yaml)"
          region = "$(yq eval '.cluster.region' config.yaml)"
          node_size = "$(yq eval '.cluster.node_size' config.yaml)"
          min_nodes = $(yq eval '.cluster.min_nodes' config.yaml)
          max_nodes = $(yq eval '.cluster.max_nodes' config.yaml)
          node_count = $(yq eval '.cluster.node_count' config.yaml)
          auto_scale = $(yq eval '.cluster.auto_scale' config.yaml)
          project_name = "$(yq eval '.project.name' config.yaml)"
          github_owner = "$(yq eval '.repository.owner' config.yaml)"
          github_repository = "$(yq eval '.repository.name' config.yaml)"
          flux_target_branch = "$(yq eval '.advanced.flux.target_branch' config.yaml)"
          flux_target_path = "$(yq eval '.advanced.flux.target_path' config.yaml)"
          primary_domain = "$PRIMARY_DOMAIN"
          skip_domain_creation = $SKIP_DOMAIN_CREATION
          EOF
      
      - name: Terraform Init
        uses: nick-fields/retry@v2
        with:
          timeout_minutes: 20
          max_attempts: 3
          retry_wait_seconds: 30
          command: |
            terraform init \
              -backend-config="access_key=${{ secrets.SPACES_ACCESS_KEY_ID }}" \
              -backend-config="secret_key=${{ secrets.SPACES_SECRET_ACCESS_KEY }}"
        env:
          TF_VAR_do_token: ${{ secrets.DIGITALOCEAN_TOKEN }}
          TF_VAR_spaces_access_key: ${{ secrets.SPACES_ACCESS_KEY_ID }}
          TF_VAR_spaces_secret_key: ${{ secrets.SPACES_SECRET_ACCESS_KEY }}
      
      - name: Backup Terraform State
        id: backup-state
        run: |
          # Create backup of current terraform state before apply
          if terraform state list > /dev/null 2>&1 && [ -n "$(terraform state list)" ]; then
            echo "Creating Terraform state backup..."
            BACKUP_FILE="terraform-state-backup-$(date +%Y%m%d-%H%M%S).tfstate"
            terraform state pull > "$BACKUP_FILE"
            
            # Store backup info for potential rollback
            echo "backup-file=$BACKUP_FILE" >> $GITHUB_OUTPUT
            echo "backup-created=true" >> $GITHUB_OUTPUT
            echo "âœ“ State backup created: $BACKUP_FILE"
          else
            echo "No existing state to backup (first deployment)"
            echo "backup-created=false" >> $GITHUB_OUTPUT
          fi
        env:
          TF_VAR_do_token: ${{ secrets.DIGITALOCEAN_TOKEN }}
          TF_VAR_spaces_access_key: ${{ secrets.SPACES_ACCESS_KEY_ID }}
          TF_VAR_spaces_secret_key: ${{ secrets.SPACES_SECRET_ACCESS_KEY }}
      
      - name: Terraform Plan
        uses: nick-fields/retry@v2
        with:
          timeout_minutes: 20
          max_attempts: 3
          retry_wait_seconds: 60
          command: terraform plan
        env:
          TF_VAR_do_token: ${{ secrets.DIGITALOCEAN_TOKEN }}
          TF_VAR_spaces_access_key: ${{ secrets.SPACES_ACCESS_KEY_ID }}
          TF_VAR_spaces_secret_key: ${{ secrets.SPACES_SECRET_ACCESS_KEY }}
          TF_VAR_github_token: ${{ secrets.GH_TOKEN }}
          TF_VAR_sops_age_private_key: ${{ secrets.SOPS_AGE_PRIVATE_KEY }}
      
      - name: Terraform Apply
        uses: nick-fields/retry@v2
        with:
          timeout_minutes: 20
          max_attempts: 3
          retry_wait_seconds: 120
          command: terraform apply -auto-approve
        env:
          TF_VAR_do_token: ${{ secrets.DIGITALOCEAN_TOKEN }}
          TF_VAR_spaces_access_key: ${{ secrets.SPACES_ACCESS_KEY_ID }}
          TF_VAR_spaces_secret_key: ${{ secrets.SPACES_SECRET_ACCESS_KEY }}
          TF_VAR_github_token: ${{ secrets.GH_TOKEN }}
          TF_VAR_sops_age_private_key: ${{ secrets.SOPS_AGE_PRIVATE_KEY }}
      
      - name: Store Backup Info for Rollback
        id: store-backup
        run: |
          echo "backup-file=${{ steps.backup-state.outputs.backup-file }}" >> $GITHUB_OUTPUT
          echo "backup-created=${{ steps.backup-state.outputs.backup-created }}" >> $GITHUB_OUTPUT
      
      - name: Update Kubeconfig Secret
        env:
          GH_TOKEN: ${{ secrets.GH_TOKEN }}
        run: |
          # Get kubeconfig from Terraform output and base64 encode it
          KUBECONFIG_CONTENT=$(terraform output -raw kubeconfig | base64 -w 0)
          
          # Update GitHub secret
          echo "$KUBECONFIG_CONTENT" | gh secret set KUBECONFIG --repo ${{ github.repository }}

  generate-encrypted-secrets:
    name: Generate Encrypted Secrets
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: [deploy-infrastructure]
    steps:
      - uses: actions/checkout@v4
        with:
          token: ${{ secrets.GH_TOKEN }}
      
      - name: Setup tools
        uses: ./.github/actions/setup-tools
      
      - name: Setup environment
        env:
          DIGITALOCEAN_TOKEN: ${{ secrets.DIGITALOCEAN_TOKEN }}
          GITHUB_TOKEN: ${{ secrets.GH_TOKEN }}
          SOPS_AGE_PRIVATE_KEY: ${{ secrets.SOPS_AGE_PRIVATE_KEY }}
        run: |
          # Create .envrc.secrets with all required values
          cat > .envrc.secrets << EOF
          export DIGITALOCEAN_TOKEN="${DIGITALOCEAN_TOKEN}"
          export GITHUB_TOKEN="${GITHUB_TOKEN}"
          export SOPS_AGE_PRIVATE_KEY="${SOPS_AGE_PRIVATE_KEY}"
          
          # Load all generated secrets (these would be set in previous job)
          export KEYCLOAK_DB_PASSWORD="$(openssl rand -base64 32 | tr -d =)"
          export KEYCLOAK_ADMIN_PASSWORD="$(openssl rand -base64 32 | tr -d =)"
          export MATTERMOST_DB_PASSWORD="$(openssl rand -base64 32 | tr -d =)"
          export MATTERMOST_OAUTH_CLIENT_ID="mattermost-oauth-$(openssl rand -hex 6)"
          export MATTERMOST_OAUTH_CLIENT_SECRET="$(openssl rand -base64 48 | tr -d =)"
          export NEXTCLOUD_DB_PASSWORD="$(openssl rand -base64 32 | tr -d =)"
          export NEXTCLOUD_OIDC_CLIENT_ID="nextcloud-oidc-$(openssl rand -hex 6)"
          export NEXTCLOUD_OIDC_CLIENT_SECRET="$(openssl rand -base64 48 | tr -d =)"
          export MAILU_OAUTH2_CLIENT_ID="mailu-oauth2-$(openssl rand -hex 6)"
          export MAILU_OAUTH2_CLIENT_SECRET="$(openssl rand -base64 48 | tr -d =)"
          export MAILU_OAUTH2_COOKIE_SECRET="$(openssl rand -base64 64 | tr -d =)"
          EOF
      
      - name: Generate encrypted secrets
        run: |
          source .envrc.secrets
          ./scripts/generate-encrypted-secrets
      
      - name: Commit encrypted secrets and domain updates
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add flux/clusters/cumulus/*/secrets.enc.yaml
          git add flux/clusters/cumulus/*/ingress*.yaml
          git add flux/clusters/cumulus/*/release.yaml
          git add flux/clusters/cumulus/*/realm-*.yaml
          
          # Check if there are any changes to commit
          if git diff --staged --quiet; then
            echo "No changes to commit"
            exit 0
          fi
          
          git commit -m "feat: add encrypted secrets and update domain references for cluster deployment

          ðŸ¤– Generated with GitHub Actions
          
          Co-Authored-By: GitHub Actions <noreply@github.com>"
          
          # Handle potential push conflicts by rebasing
          MAX_RETRIES=3
          RETRY_COUNT=0
          
          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            if git push; then
              echo "Successfully pushed changes"
              break
            else
              echo "Push failed, attempting to rebase and retry..."
              git pull --rebase
              RETRY_COUNT=$((RETRY_COUNT + 1))
              
              if [ $RETRY_COUNT -eq $MAX_RETRIES ]; then
                echo "Failed to push after $MAX_RETRIES retries"
                exit 1
              fi
            fi
          done

  wait-for-flux:
    name: Wait for Flux Reconciliation
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: [validate-config, generate-encrypted-secrets]
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup tools
        uses: ./.github/actions/setup-tools
      
      - name: Setup kubeconfig
        env:
          KUBECONFIG_CONTENT: ${{ secrets.KUBECONFIG }}
        run: |
          mkdir -p ~/.kube
          echo "${KUBECONFIG_CONTENT}" | base64 -d > ~/.kube/config
          chmod 600 ~/.kube/config
      
      - name: Wait for Flux reconciliation
        timeout-minutes: 15
        run: |
          echo "Waiting for Flux to reconcile..."
          
          # Wait for flux-system to be ready
          kubectl wait --for=condition=ready gitrepository/flux-system -n flux-system --timeout=600s
          
          echo "âœ… Flux system is ready"
          
          # Show status
          flux get all -n flux-system
          kubectl get pods -A
      
      - name: Health Check Deployment
        id: health-check
        timeout-minutes: 10
        run: |
          echo "Performing comprehensive health checks..."
          
          # Check core system pods
          echo "ðŸ” Checking core system components..."
          if ! kubectl get pods -n kube-system | grep -E "(coredns|kube-proxy)" | grep -v Running; then
            echo "âœ… Core system components are healthy"
          else
            echo "âŒ Core system components have issues"
            exit 1
          fi
          
          # Check Flux system health
          echo "ðŸ” Checking Flux system health..."
          if kubectl wait --for=condition=ready pods -l app.kubernetes.io/part-of=flux -n flux-system --timeout=300s; then
            echo "âœ… Flux system is healthy"
          else
            echo "âŒ Flux system health check failed"
            exit 1
          fi
          
          # Check if any critical workloads failed to start
          echo "ðŸ” Checking for failed workloads..."
          FAILED_PODS=$(kubectl get pods -A --field-selector=status.phase=Failed --no-headers 2>/dev/null | wc -l)
          if [ "$FAILED_PODS" -gt 0 ]; then
            echo "âš ï¸ Found $FAILED_PODS failed pods:"
            kubectl get pods -A --field-selector=status.phase=Failed
            # Don't fail on this as some pods might fail temporarily
          fi
          
          # Check cluster resource usage
          echo "ðŸ” Checking cluster resource usage..."
          kubectl top nodes --no-headers 2>/dev/null || echo "âš ï¸ Metrics not available yet"
          
          echo "âœ… Health checks completed successfully"
      
      - name: Setup Terraform for DNS Update
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ needs.validate-config.outputs.terraform-version }}
      
      - name: Install doctl
        uses: digitalocean/action-doctl@v2
        with:
          token: ${{ secrets.DIGITALOCEAN_TOKEN }}
      
      - name: Update DNS Records
        env:
          TF_VAR_do_token: ${{ secrets.DIGITALOCEAN_TOKEN }}
          TF_VAR_spaces_access_key: ${{ secrets.SPACES_ACCESS_KEY_ID }}
          TF_VAR_spaces_secret_key: ${{ secrets.SPACES_SECRET_ACCESS_KEY }}
          TF_VAR_github_token: ${{ secrets.GH_TOKEN }}
          TF_VAR_sops_age_private_key: ${{ secrets.SOPS_AGE_PRIVATE_KEY }}
          DIGITALOCEAN_TOKEN: ${{ secrets.DIGITALOCEAN_TOKEN }}
        run: |
          # Use the update-dns-records script which handles both IP and hostname cases
          ./scripts/update-dns-records || {
            echo "âš ï¸  Automatic DNS update failed. You can manually update later with:"
            echo "  ./scripts/update-dns-records"
            exit 0
          }

  destroy-infrastructure:
    name: Destroy Infrastructure
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: validate-config
    if: github.event.inputs.destroy == 'true'
    defaults:
      run:
        working-directory: terraform/digitalocean
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ needs.validate-config.outputs.terraform-version }}
      
      - name: Terraform Init
        uses: nick-fields/retry@v2
        with:
          timeout_minutes: 20
          max_attempts: 3
          retry_wait_seconds: 30
          command: |
            terraform init \
              -backend-config="access_key=${{ secrets.SPACES_ACCESS_KEY_ID }}" \
              -backend-config="secret_key=${{ secrets.SPACES_SECRET_ACCESS_KEY }}"
        env:
          TF_VAR_do_token: ${{ secrets.DIGITALOCEAN_TOKEN }}
          TF_VAR_spaces_access_key: ${{ secrets.SPACES_ACCESS_KEY_ID }}
          TF_VAR_spaces_secret_key: ${{ secrets.SPACES_SECRET_ACCESS_KEY }}
      
      - name: Terraform Destroy
        uses: nick-fields/retry@v2
        with:
          timeout_minutes: 20
          max_attempts: 3
          retry_wait_seconds: 120
          command: terraform destroy -auto-approve
        env:
          TF_VAR_do_token: ${{ secrets.DIGITALOCEAN_TOKEN }}
          TF_VAR_spaces_access_key: ${{ secrets.SPACES_ACCESS_KEY_ID }}
          TF_VAR_spaces_secret_key: ${{ secrets.SPACES_SECRET_ACCESS_KEY }}
          TF_VAR_github_token: ${{ secrets.GH_TOKEN }}
          TF_VAR_sops_age_private_key: ${{ secrets.SOPS_AGE_PRIVATE_KEY }}

  rollback-infrastructure:
    name: Rollback Infrastructure on Failure
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: [deploy-infrastructure, setup-secrets, validate-config]
    if: failure() && needs.deploy-infrastructure.outputs.backup-created == 'true'
    defaults:
      run:
        working-directory: terraform/digitalocean
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ needs.validate-config.outputs.terraform-version }}
      
      - name: Terraform Init for Rollback
        uses: nick-fields/retry@v2
        with:
          timeout_minutes: 20
          max_attempts: 3
          retry_wait_seconds: 30
          command: |
            terraform init \
              -backend-config="access_key=${{ secrets.SPACES_ACCESS_KEY_ID }}" \
              -backend-config="secret_key=${{ secrets.SPACES_SECRET_ACCESS_KEY }}"
        env:
          TF_VAR_do_token: ${{ secrets.DIGITALOCEAN_TOKEN }}
          TF_VAR_spaces_access_key: ${{ secrets.SPACES_ACCESS_KEY_ID }}
          TF_VAR_spaces_secret_key: ${{ secrets.SPACES_SECRET_ACCESS_KEY }}
      
      - name: Restore Terraform State
        run: |
          echo "Deployment failed, attempting to restore previous state..."
          BACKUP_FILE="${{ needs.deploy-infrastructure.outputs.backup-file }}"
          
          if [ -f "$BACKUP_FILE" ]; then
            echo "Restoring state from backup: $BACKUP_FILE"
            terraform state push "$BACKUP_FILE"
            echo "âœ“ State restored from backup"
          else
            echo "âš ï¸ Backup file not found, manual intervention may be required"
            exit 1
          fi
        env:
          TF_VAR_do_token: ${{ secrets.DIGITALOCEAN_TOKEN }}
          TF_VAR_spaces_access_key: ${{ secrets.SPACES_ACCESS_KEY_ID }}
          TF_VAR_spaces_secret_key: ${{ secrets.SPACES_SECRET_ACCESS_KEY }}
      
      - name: Verify Rollback
        run: |
          echo "Verifying rollback by checking current state..."
          terraform plan -detailed-exitcode
          
          if [ $? -eq 0 ]; then
            echo "âœ“ Rollback successful - infrastructure matches backed up state"
          else
            echo "âš ï¸ Rollback verification failed - manual intervention required"
          fi
        env:
          TF_VAR_do_token: ${{ secrets.DIGITALOCEAN_TOKEN }}
          TF_VAR_spaces_access_key: ${{ secrets.SPACES_ACCESS_KEY_ID }}
          TF_VAR_spaces_secret_key: ${{ secrets.SPACES_SECRET_ACCESS_KEY }}
          TF_VAR_github_token: ${{ secrets.GH_TOKEN }}
          TF_VAR_sops_age_private_key: ${{ secrets.SOPS_AGE_PRIVATE_KEY }}

  cleanup-on-failure:
    name: Cleanup Partial Deployment
    runs-on: ubuntu-latest
    timeout-minutes: 15
    needs: [validate-config, setup-secrets, deploy-infrastructure, generate-encrypted-secrets, wait-for-flux]
    if: failure()
    steps:
      - uses: actions/checkout@v4
      
      - name: Setup tools
        uses: ./.github/actions/setup-tools
        with:
          tools: 'kubectl,flux,doctl'
      
      - name: Cleanup Kubernetes Resources on Flux Failure
        if: failure() && needs.wait-for-flux.result == 'failure'
        env:
          KUBECONFIG_CONTENT: ${{ secrets.KUBECONFIG }}
          DIGITALOCEAN_TOKEN: ${{ secrets.DIGITALOCEAN_TOKEN }}
        run: |
          if [ -n "$KUBECONFIG_CONTENT" ]; then
            echo "Setting up kubeconfig for cleanup..."
            mkdir -p ~/.kube
            echo "${KUBECONFIG_CONTENT}" | base64 -d > ~/.kube/config
            chmod 600 ~/.kube/config
            
            echo "Cleaning up failed Flux installation..."
            
            # Try to uninstall flux if it was partially installed
            flux uninstall --silent || echo "Flux uninstall completed or was not installed"
            
            # Remove any stuck finalizers from flux-system namespace
            kubectl get namespace flux-system -o json | jq '.spec.finalizers = []' | kubectl replace --raw "/api/v1/namespaces/flux-system/finalize" -f - || echo "No flux-system namespace to clean"
            
            echo "âœ“ Kubernetes cleanup completed"
          else
            echo "No kubeconfig available, skipping Kubernetes cleanup"
          fi
      
      - name: Cleanup Orphaned DigitalOcean Resources
        env:
          DIGITALOCEAN_TOKEN: ${{ secrets.DIGITALOCEAN_TOKEN }}
        run: |
          echo "Checking for orphaned DigitalOcean resources..."
          
          # List Load Balancers that might be left behind
          if doctl compute load-balancer list --format ID,Name,Status | grep -q "traefik\|ingress"; then
            echo "âš ï¸ Found potentially orphaned load balancers"
            doctl compute load-balancer list --format ID,Name,Status
            echo "Please manually review and cleanup if needed"
          fi
          
          # List Volumes that might be left behind
          if doctl compute volume list --format ID,Name,Size | grep -q "pvc-\|vol-"; then
            echo "âš ï¸ Found potentially orphaned volumes"
            doctl compute volume list --format ID,Name,Size
            echo "Please manually review and cleanup if needed"
          fi
          
          echo "âœ“ Resource cleanup check completed"
      
      - name: Create Cleanup Summary
        run: |
          cat > deployment-failure-summary.md << EOF
          # Deployment Failure Summary
          
          **Workflow:** ${{ github.workflow }}
          **Run ID:** ${{ github.run_id }}
          **Failed at:** $(date -u)
          **Branch:** ${{ github.ref_name }}
          **Commit:** ${{ github.sha }}
          
          ## Failure Details
          - Deploy Infrastructure: ${{ needs.deploy-infrastructure.result }}
          - Generate Secrets: ${{ needs.generate-encrypted-secrets.result }}  
          - Wait for Flux: ${{ needs.wait-for-flux.result }}
          
          ## Cleanup Actions Taken
          - State backup: ${{ needs.deploy-infrastructure.outputs.backup-created == 'true' && 'âœ“ Created' || 'âœ— Not created' }}
          - Rollback attempted: ${{ needs.rollback-infrastructure.result == 'success' && 'âœ“ Successful' || needs.rollback-infrastructure.result == 'failure' && 'âœ— Failed' || '- Not applicable' }}
          - Kubernetes cleanup: ${{ needs.wait-for-flux.result == 'failure' && 'âœ“ Performed' || '- Not needed' }}
          
          ## Next Steps
          1. Review the workflow logs for specific error details
          2. Check DigitalOcean console for any orphaned resources
          3. Verify GitHub repository secrets are correctly configured
          4. Re-run deployment after addressing the root cause
          
          ## Manual Cleanup Commands
          If needed, you can run these commands manually:
          \`\`\`bash
          # Check cluster status
          ./scripts/kubeconfig-get
          kubectl get pods -A
          
          # Complete infrastructure cleanup
          ./scripts/cluster-destroy
          
          # Reset secrets if needed
          ./scripts/generate-secrets
          \`\`\`
          EOF
          
          echo "Deployment failure summary created"
          cat deployment-failure-summary.md
      
      - name: Upload Failure Summary
        uses: actions/upload-artifact@v4
        with:
          name: deployment-failure-summary-${{ github.run_id }}
          path: deployment-failure-summary.md
          retention-days: 30